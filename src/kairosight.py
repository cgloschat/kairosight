#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import json
import os
import sys
import time
import math
import numpy as np
import pandas as pd
from decimal import Decimal
from pathlib import Path, PurePath
from random import random

from util.preparation import open_stack, reduce_stack, mask_generate, mask_apply, img_as_uint, rescale
from util.processing import normalize_stack, filter_drift, invert_signal, \
    filter_spatial, calculate_snr, map_snr, find_tran_act
from util.analysis import find_tran_start, find_tran_end, calc_tran_duration, calc_ensemble, map_tran_analysis, DUR_MAX
from ui.KairoSight_WindowMDI import Ui_WindowMDI
from ui.KairoSight_WindowMain import Ui_WindowMain
from PyQt5.QtCore import QObject, pyqtSignal, Qt
from PyQt5.QtWidgets import QApplication, QWidget, QMainWindow, QFileDialog
from PyQt5.QtGui import QColor
import pyqtgraph as pg
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import matplotlib.colors as colors
import matplotlib.font_manager as fm
from mpl_toolkits.axes_grid1.inset_locator import inset_axes
from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar
import util.ScientificColourMaps5 as SCMaps
from tests.intergration.test_Map import fontsize3, fontsize4, marker1, marker3, gray_heavy, \
    color_snr, cmap_snr, cmap_activation, ACT_MAX_PIG_LV, ACT_MAX_PIG_WHOLE, cmap_duration, \
    add_map_colorbar_stats


class WindowMDI(QMainWindow, Ui_WindowMDI):
    """Customization for Ui_MDIMainWindow, and MDI main window"""

    def __init__(self, parent=None):
        # initialization of the superclass
        super(WindowMDI, self).__init__(parent)
        # setup the GUI --> function generated by pyuic5
        self.setupUi(self)
        self.raise_()
        # connect the signals with the slots
        # self.actionLoad.triggered.connect(self.open_tiff)
        # self.actionClose.triggered.connect(self.close)
        self.actionTIFF.triggered.connect(self.open_tiff)

    def open_tiff(self, file=None):
        """Open a WindowMain with a TIFF stack within the MDI area"""
        if file:
            print('Opening tiff with passed filepath: ' + file)
        else:
            # Use a QFileDialog to get filepath if none provided
            file, mask = QFileDialog.getOpenFileName(self, 'Open a .tif/.tiff stack')

        if file:
            self.status_print('Opening ' + file + ' ...')
            f_purepath = PurePath(file)
            f_ext = f_purepath.suffix
            if f_ext == '.pcoraw':
                # Change .pcoraw files to .tif?
                # os.rename(file, f_name + '.tif')
                p = Path(file)
                p.rename(p.with_suffix('.tif'))
                print('* .pcoraw covnerted to a .tif')
                # Use a QFileDialog to get the new filepath
                file, mask = QFileDialog.getOpenFileName(self, 'Open a .tif/.tiff stack')
                self.status_print('Opening ' + file + ' ...')
                f_purepath = PurePath(file)

            f_display = str(f_purepath.parent) + '\\' + '\t' + f_purepath.stem + ' ' + f_purepath.suffix
            print('file (path name ext): ' + f_display)
            try:
                # Create QMdiSubWindow with Ui_WidgetTiff
                sub = WindowMain(parent=self, file_purepath=f_purepath)
                sub.setObjectName(str(file))
                sub.setWindowTitle('TIFF View: ' + f_display)
                # Add and connect QMdiSubWindow to MDI
                self.mdiArea.addSubWindow(sub)
                sub.show()
                self.status_print('Opened ' + file)
            except:
                exc_type, exc_value, tb = sys.exc_info()
                exc_lineno = tb.tb_lineno
                self.status_print('ERROR at line {}: {}'.format(exc_lineno, exc_value))
        else:
            print('path is None')
            self.status_print('Open cancelled')

    def status_print(self, text):
        self.statusBar().showMessage(text)


class Stream(QObject):
    newText = pyqtSignal(str)

    def write(self, text):
        self.newText.emit(str(text))


class WindowMain(QWidget, Ui_WindowMain):
    """Customization for Ui_WindowMain"""

    def __init__(self, parent=None, file_purepath=None):
        super(WindowMain, self).__init__(parent)  # initialization of the superclass
        self.WindowMDI = parent
        self.setupUi(self)  # setup the UI
        sys.stdout = Stream(newText=self.feedback_action)
        self.next_buttons = []
        self.setup_next_buttons()
        self.skip_checkboxes = []
        self.setup_skip_buttons()

        # Customize Feedback Text
        self.textBrowser_Feedback.setStyleSheet('background: rgb(10, 10, 10)')

        # Import file for this window
        self.file_purepath = file_purepath
        self.file_path_str = str(self.file_purepath)
        self.project_path_str = str(self.file_purepath.parent) + '\\' + str(self.file_purepath.stem) + '_ks_project'
        self.video_data_raw, self.stack_real_meta = open_stack(source=self.file_path_str)
        self.frame_n = self.video_data_raw.shape[0]
        self.width_raw, self.height_raw = self.video_data_raw.shape[2], self.video_data_raw.shape[1]

        # Copy imported video to preserve it
        self.video_data = self.video_data_raw.copy()
        self.video_time = None

        # Setup project directory and files
        self.project_props_prp = {'fps': None, 'scale': None, 'type': None, 'subject': None,
                                  'rescale': 1, 'mask': (None, None)}
        self.project_props_prc = {'norm': '0 - 1', 'invert': False, 'drift': 1, 'filter': 1, 'snr': None}
        self.project_props_ans = {'time': (None, None), 'type': None}
        self.frame_current = 0
        self.trace_xy = (0, 0)
        self.trace = None
        self.mask = None
        self.kernel_cm = None
        self.video_data_unmasked = np.empty_like(self.video_data)
        self.setup_project()

        # Setup trace preview UI
        self.plot_preview = self.widgetPreviewPlot.addPlot()
        self.traceXSpinBox.valueChanged.connect(lambda: self.update_inputs(self.traceXSpinBox))
        self.traceYSpinBox.valueChanged.connect(lambda: self.update_inputs(self.traceYSpinBox))
        self.pushButtonTraceCenter.clicked.connect(lambda: self.update_inputs(self.pushButtonTraceCenter))
        self.trace_crosshair = pg.CrosshairROI(self.trace_xy,
                                               [self.video_data.shape[2] // 20, self.video_data.shape[1] // 20],
                                               pen=(2, 9))
        self.trace_crosshair.sigRegionChanged.connect(lambda: self.update_trace(live=True))
        self.trace_crosshair.setPen(color='54FF00')
        self.graphicsView.p1.addItem(self.trace_crosshair)
        # self.trace_frameline = pg.LinearRegionItem([self.frame_current, self.frame_current], movable=False)
        # self.trace_frameline = pg.InfiniteLine(pg.QtCore.QPointF(self.frame_current, 0), 90, movable=False)
        # self.trace_frameline.setZValue(1)
        # self.plot_preview.addItem(self.trace_frameline)

        # Setup and connect input UI components
        self.kernelPixelsSpinBox.valueChanged.connect(lambda: self.update_inputs(self.kernelPixelsSpinBox))
        self.horizontalScrollBar.valueChanged['int'].connect(self.update_video)
        self.horizontalScrollBar.setMinimum(1)
        self.horizontalScrollBar.setMaximum(self.frame_n)
        self.lcdNumber_frame_n.display(self.frame_n)
        self.startFrameSpinBox.setMaximum(self.frame_n - 1)
        self.endFrameSpinBox.setMaximum(self.frame_n)
        self.endFrameSpinBox.setValue(self.frame_n)
        self.graphicsView.p1.setAspectLocked(True)

        # Set histogram to image levels and use a manual range
        self.graphicsView.histogram.setLevels(self.video_data.min(), self.video_data.max())
        self.graphicsView.histogram.setHistogramRange(self.video_data.min(), self.video_data.max())
        self.WindowMDI.status_print('- - -')

    def __del__(self):
        sys.stdout = sys.__stdout__

    def setup_project(self):
        """Create a new or load an existing project folder"""
        try:
            os.mkdir(self.project_path_str)
            self.feedback_action('Project folder created : \\' +
                                 str(self.file_purepath.stem) + '_ks_project\\')
        except FileExistsError:
            self.feedback_action('Project folder already exists : \\' +
                                 str(self.file_purepath.stem) + '_ks_project\\')
            # If the project folder already exists, load/create the properties
            try:  # Preparation
                with open(self.project_path_str + '\\' + str(self.file_purepath.stem) + '.ks_prep', 'r') as openfile:
                    self.project_props_prp = json.load(openfile)
                    self.feedback_action('Loaded Preparation properties : ' +
                                         str(self.file_purepath.stem) + '.ks_prep')
                self.import_parameters()
            except FileNotFoundError:
                with open(self.project_path_str + '\\' + str(self.file_purepath.stem) + '.ks_prep', "w") as outfile:
                    json.dump(self.project_props_prp, outfile)
            try:  # Processing
                with open(self.project_path_str + '\\' + str(self.file_purepath.stem) + '.ks_proc', 'r') as openfile:
                    self.project_props_prc = json.load(openfile)
                    self.feedback_action('Loaded Processing properties : ' +
                                         str(self.file_purepath.stem) + '.ks_proc')
                self.import_parameters()
            except FileNotFoundError:
                with open(self.project_path_str + '\\' + str(self.file_purepath.stem) + '.ks_proc', "w") as outfile:
                    json.dump(self.project_props_prc, outfile)
            try:  # Analysis
                with open(self.project_path_str + '\\' + str(self.file_purepath.stem) + '.ks_anys', 'r') as openfile:
                    self.project_props_ans = json.load(openfile)
                    self.feedback_action('Loaded Analysis properties : ' +
                                         str(self.file_purepath.stem) + '.ks_anys')
                self.import_parameters()
            except FileNotFoundError:
                with open(self.project_path_str + '\\' + str(self.file_purepath.stem) + '.ks_anys', "w") as outfile:
                    json.dump(self.project_props_ans, outfile)

    def update_video(self, frame=0):
        """Updates the video frame drawn to its canvas"""
        self.frame_current = frame
        # self.trace_frameline.setValue(self.frame_current)
        # Update ImageItem(s) with a frame in a stack
        self.graphicsView.img_item.setImage(self.video_data[frame - 1, ...])
        # Notify histogram items of image change
        self.graphicsView.histogram.regionChanged()
        self.traceXSpinBox.setMaximum(self.video_data.shape[2] - 1)
        self.traceYSpinBox.setMaximum(self.video_data.shape[1] - 1)

    def update_trace(self, live=False):
        """Updates the trace drawn to its canvas"""
        if not live:
            self.trace_crosshair.setPos(self.trace_xy)
        else:
            self.trace_xy = (int(self.trace_crosshair.pos().x()), int(self.trace_crosshair.pos().y()))
        self.trace = self.video_data[:, min(self.trace_xy[1], self.video_data.shape[1] - 1),
                     min(self.trace_xy[0], self.video_data.shape[2] - 1)]
        self.plot_preview.plot(self.trace, pen=pg.mkPen(color='54FF00'), clear=True)  # TODO update x-axis to time
        # self.trace_frameline.(self.frame_current)
        # y = np.arange(start=signal_stack.min(), stop=signal_stack.min())
        # self.plot_preview.plot(x=self.frame_n, y=y, brush=pg.mkPen(color='FF5400'), clear=True)
        # self.update_video(self.frame_current)
        # self.plot_preview.plot(self.trace_xy[0], self.trace_xy[1], pen=None,
        #                        symbol='t1', symbolPen=None, symbolSize=10, symbolBrush=(255, 5, 5, 200))

    def update_parameters(self, step_name):
        """Update user parameters with input fields"""
        if step_name == 'Properties':
            try:
                self.project_props_prp['fps'] = float(self.frameRateLineEdit.text())
            except ValueError:
                self.feedback_action('Preparation step {} ERROR : Bad entry in "Frame Rate (fps)",'
                                     ' must be a number (e.g 505.5)'.format(step_name), success=False)
                raise ValueError
            try:
                self.project_props_prp['scale'] = float(self.scaleLineEdit.text())
            except ValueError:
                self.feedback_action('Preparation step {} ERROR : Bad entry in "Scale (px/cm)",'
                                     ' must be a number (e.g 101.4362)'.format(step_name), success=False)
                raise ValueError
            with open(self.project_path_str + '\\' + str(self.file_purepath.stem) + '.ks_prep', "w") as outfile:
                json.dump(self.project_props_prp, outfile)
        elif step_name == 'Bin':
            try:
                self.project_props_prp['rescale'] = int(self.rescaleSpinBox.value())
            except:
                exc_type, exc_value, tb = sys.exc_info()
                exc_lineno = tb.tb_lineno
                real_error = str(exc_type) + ' : ' + str(exc_value)
                self.feedback_action('Preparation step {} ERROR at line {}: {}'
                                     .format(step_name, exc_lineno, real_error), success=False)
            with open(self.project_path_str + '\\' + str(self.file_purepath.stem) + '.ks_prep', "w") as outfile:
                json.dump(self.project_props_prp, outfile)
        elif step_name == 'Mask':
            try:
                self.project_props_prp['mask'] = (int(self.darkCutoffSpinBox.value()),
                                                  int(self.lightCutoffSpinBox.value()))
            except:
                exc_type, exc_value, tb = sys.exc_info()
                exc_lineno = tb.tb_lineno
                real_error = str(exc_type) + ' : ' + str(exc_value)
                self.feedback_action('Preparation step {} ERROR at line {} : {}'
                                     .format(step_name, exc_lineno, real_error), success=False)
            with open(self.project_path_str + '\\' + str(self.file_purepath.stem) + '.ks_prep', "w") as outfile:
                json.dump(self.project_props_prp, outfile)
        elif step_name == 'Normalize':
            try:
                self.project_props_prc['norm'] = self.normTypeComboBox.currentText()
                # TODO add drift, invert fields
            except:
                exc_type, exc_value, tb = sys.exc_info()
                exc_lineno = tb.tb_lineno
                real_error = str(exc_type) + ' : ' + str(exc_value)
                self.feedback_action('Processing step {} ERROR at line {} : {}'
                                     .format(step_name, exc_lineno, real_error), success=False)
            with open(self.project_path_str + '\\' + str(self.file_purepath.stem) + '.ks_proc', "w") as outfile:
                json.dump(self.project_props_prc, outfile)
        elif step_name == 'Filter':
            try:
                self.project_props_prc['filter'] = int(self.kernelPixelsSpinBox.value())
            except:
                exc_type, exc_value, tb = sys.exc_info()
                exc_lineno = tb.tb_lineno
                real_error = str(exc_type) + ' : ' + str(exc_value)
                self.feedback_action('Processing step {} ERROR at line {} : {}'
                                     .format(step_name, exc_lineno, real_error), success=False)
            with open(self.project_path_str + '\\' + str(self.file_purepath.stem) + '.ks_proc', "w") as outfile:
                json.dump(self.project_props_prc, outfile)
        # TODO add snr fields
        elif step_name == 'Time Crop':
            try:
                self.project_props_ans['time'] = (int(self.startFrameSpinBox.value()),
                                                  int(self.endFrameSpinBox.value()))
            except:
                exc_type, exc_value, tb = sys.exc_info()
                exc_lineno = tb.tb_lineno
                real_error = str(exc_type) + ' : ' + str(exc_value)
                self.feedback_action('Analysis step {} ERROR at line {} : {}'
                                     .format(step_name, exc_lineno, real_error), success=False)
            with open(self.project_path_str + '\\' + str(self.file_purepath.stem) + '.ks_anys', "w") as outfile:
                json.dump(self.project_props_ans, outfile)
        elif step_name == 'Analyze':
            try:
                self.project_props_ans['type'] = str(self.analyzeTypeComboBox.currentText())
            except:
                exc_type, exc_value, tb = sys.exc_info()
                exc_lineno = tb.tb_lineno
                real_error = str(exc_type) + ' : ' + str(exc_value)
                self.feedback_action('Analysis step {} ERROR at line {} : {}'
                                     .format(step_name, exc_lineno, real_error), success=False)
            with open(self.project_path_str + '\\' + str(self.file_purepath.stem) + '.ks_anys', "w") as outfile:
                json.dump(self.project_props_ans, outfile)

    def update_inputs(self, field):
        """Update connected user input fields"""
        try:
            if field is self.kernelPixelsSpinBox:
                self.kernelSizeLineEdit.setEnabled(True)
                scale_sig_figfs = len(str(self.project_props_prp['scale']).split(sep='.')[-1])
                self.kernel_cm = np.round(float(self.kernelPixelsSpinBox.value()) /
                                          (self.project_props_prp['scale'] / self.project_props_prp['rescale']),
                                          scale_sig_figfs)
                self.kernelSizeLineEdit.setText(str(self.kernel_cm))
                self.kernelSizeLineEdit.setEnabled(False)
            elif (field is self.traceXSpinBox) or (field is self.traceYSpinBox):
                self.trace_xy = (self.traceXSpinBox.value(), self.traceYSpinBox.value())
                self.update_trace()
            elif field is self.pushButtonTraceCenter:
                self.trace_xy = (int(self.video_data.shape[2] / 2),
                                 int(self.video_data.shape[1] / 2))
                self.traceXSpinBox.setValue(self.trace_xy[0])
                self.traceYSpinBox.setValue(self.trace_xy[1])
                self.update_trace()
        except:
            exc_type, exc_value, tb = sys.exc_info()
            exc_lineno = tb.tb_lineno
            real_error = str(exc_type) + ' : ' + str(exc_value)
            self.feedback_action('Update Input ERROR at line {} : {}'.format(exc_lineno, real_error), success=False)

    def import_parameters(self):
        """Populate user input fields with imported parameters"""  # TODO skip if None loaded
        if self.project_props_prp['fps']:
            self.frameRateLineEdit.setText(str(self.project_props_prp['fps']))
        if self.project_props_prp['scale']:
            self.scaleLineEdit.setText(str(self.project_props_prp['scale']))
        if self.project_props_prp['subject']:
            pass  # TODO create 'subject' UI
        else:
            self.project_props_prp['subject'] = str(self.file_purepath.stem)
        if self.project_props_prp['rescale']:
            self.rescaleSpinBox.setValue(int(self.project_props_prp['rescale']))
        if self.project_props_prp['mask'][0]:
            self.darkCutoffSpinBox.setValue(int(self.project_props_prp['mask'][0]))
            self.lightCutoffSpinBox.setValue(int(self.project_props_prp['mask'][1]))
        # TODO add norm fields
        if self.project_props_prc['filter']:
            self.kernelPixelsSpinBox.setValue(int(self.project_props_prc['filter']))
            self.update_inputs(self.kernelPixelsSpinBox)
        # TODO add snr fields
        if self.project_props_ans['time'][0]:
            self.startFrameSpinBox.setValue(int(self.project_props_ans['time'][0]))
            self.endFrameSpinBox.setValue(int(self.project_props_ans['time'][1]))
        if self.project_props_ans['type']:
            text = str(self.project_props_ans['type'])
            index = self.analyzeTypeComboBox.findText(text, Qt.MatchFixedString)
            if index >= 0:
                self.analyzeTypeComboBox.setCurrentIndex(index)

    def export_map(self, map_data, map_type):
        if map_type == 'SNR':
            map_title = 'Signal-to-Noise Ratio (SNR)'
            map_cmap = cmap_snr
            map_unit = 'SNR'
            map_file_name = 'proc_snr'
            # map_min_display, map_max_display = 0, 100
        elif map_type == 'Activation':
            map_title = map_type
            map_cmap = cmap_activation
            map_unit = 'ms'
            map_file_name = 'anys_activation'
            # map_min_display, map_max_display = 0, ACT_MAX_PIG_WHOLE
        elif map_type == 'Duration':
            duration = self.durationPerSpinBox.value()
            map_title = 'Duration-{}%'.format(duration)
            map_cmap = cmap_duration
            map_unit = 'ms'
            map_file_name = 'anys_duration' + str(duration)
            # map_min_display, map_max_display = 0, DUR_MAX
        else:
            map_title = 'map_title'
            map_cmap = SCMaps.grayC.reversed()
            map_unit = 'map_unit'
            map_file_name = 'map_file_name'
            # map_min_display, map_max_display = 0, 100

        map_data_trace = map_data[self.trace_xy[1]][self.trace_xy[0]]
        # use map min/max to exclude values
        map_min_display, map_max_display = 0, 100
        if map_type == 'SNR':
            map_min_display, map_max_display = self.snrMinSpinBox.value(), self.snrMaxSpinBox.value()
        else:
            map_min_display, map_max_display = self.mapMinSpinBox.value(), self.mapMaxSpinBox.value()
        # exclude values outside of range
        for iy, ix in np.ndindex(map_data.shape):
            if map_data[iy, ix] < map_min_display or map_data[iy, ix] > map_max_display:
                map_data[iy, ix] = np.nan
        colormap_choice = self.colormapComboBox.currentText()
        if colormap_choice == 'Orange':
            map_cmap = cmap_activation
        elif colormap_choice == 'Blue':
            map_cmap = cmap_duration
        elif colormap_choice == 'Purple':
            map_cmap = cmap_snr
        elif colormap_choice == 'Auto for Map Type':
            self.feedback_action('Generating map with default {} colormap ...'.format(map_type))
        else:
            self.feedback_action('Invalid colormap chosen : {}'.format(colormap_choice), success=False)

        fig_snr = plt.figure(figsize=(12, 8))  # _ x _ inch page
        gs0 = fig_snr.add_gridspec(2, 1, height_ratios=[0.7, 0.3])  # 2 rows, 1 column
        gs_frames = gs0[0].subgridspec(1, 3, width_ratios=[0.475, 0.475, 0.05], wspace=0.4)
        axis_prep = fig_snr.add_subplot(gs_frames[0])
        axis_map = fig_snr.add_subplot(gs_frames[1])
        # Common between the two
        for ax in [axis_prep, axis_map]:
            ax.tick_params(axis='x', labelsize=fontsize4)
            ax.tick_params(axis='y', labelsize=fontsize4)

        gs_signals = gs0[1].subgridspec(1, 3, width_ratios=[0.3, 0.3, 0.3], wspace=0.1)
        axis_min = fig_snr.add_subplot(gs_signals[0])
        axis_xy = fig_snr.add_subplot(gs_signals[1])
        axis_max = fig_snr.add_subplot(gs_signals[2])
        for ax in [axis_min, axis_xy, axis_max]:
            ax.tick_params(axis='x', labelsize=fontsize4)
            # ax.set_xlim(right=150)
            [s.set_visible(False) for s in ax.spines.values()]
            ax.tick_params(axis='x', labelsize=fontsize3, which='minor', length=3)
            ax.tick_params(axis='x', labelsize=fontsize3, which='major', length=8)
            ax.xaxis.set_major_locator(plticker.MultipleLocator(100))
            ax.xaxis.set_minor_locator(plticker.MultipleLocator(50))
            ax.set_yticks([])
            ax.set_yticklabels([])
        axis_min.set_ylabel('F (arb. u.)')
        axis_xy.set_xlabel('Time (ms)')

        # fig_snr.suptitle('{}\n{} Map'.format(self.project_props_prp['subject'], map_title))
        preparation = 'Binned x{}'.format(self.project_props_prp['rescale'])
        process = 'Mask {}, Gaussian: {} cm ({} px)'.format(self.project_props_prp['mask'],
                                                            self.kernel_cm, self.project_props_prc['filter'])
        axis_prep.set_title('{}\n{}'.format(self.project_props_prp['subject'], preparation))
        map_data = np.round(map_data, 2)
        map_min = np.nanmin(map_data)
        map_max = np.nanmax(map_data)
        map_n = np.count_nonzero(~np.isnan(map_data))
        axis_map.set_title('{} Map\n{}\n{} - {} ({} pixels)'
                           .format(map_title,
                                   process,
                                   round(map_min, 2), round(map_max, 2), map_n))

        # Frame from video (Prepped w/o mask)
        frame_cmap = SCMaps.grayC.reversed()
        frame_brightest = np.zeros_like(self.video_data_unmasked[0])  # use brightest frame to generate mask
        frame_bright_idx = 0
        for idx, frame in enumerate(self.video_data_unmasked):
            frame_brightness = np.nanmean(frame)
            if frame_brightness > np.nanmean(frame_brightest):
                frame_bright_idx = idx
                frame_brightest = frame.copy()

        frame_bright = self.video_data_raw[frame_bright_idx]
        frame_scale = self.project_props_prp['scale']
        if self.project_props_prp['rescale'] != 1:
            # frame_bright = reduce_stack(self.video_data_raw[frame_bright_idx], self.project_props_prp['rescale'])
            reduction_factor = 1 / self.project_props_prp['rescale']
            frame_bright = img_as_uint(rescale(frame_bright, reduction_factor, anti_aliasing=True, multichannel=False))
            frame_scale = frame_scale / self.project_props_prp['rescale']

        frame_cmap_norm = colors.Normalize(vmin=frame_bright.min(),
                                           vmax=frame_bright.max())
        img_prep = axis_prep.imshow(frame_bright, norm=frame_cmap_norm, cmap=frame_cmap)
        prep_scale_bar = AnchoredSizeBar(axis_prep.transData, frame_scale, size_vertical=0.2,
                                         label='1 cm', loc=4, pad=0.2, color='w', frameon=False,
                                         fontproperties=fm.FontProperties(size=7, weight='semibold'))
        axis_prep.add_artist(prep_scale_bar)
        # add colorbar (lower right of frame)
        ax_ins_img = inset_axes(axis_prep, width="5%", height="100%", loc=5,
                                bbox_to_anchor=(0.1, 0, 1, 1), bbox_transform=axis_prep.transAxes,
                                borderpad=0)
        cb_img = plt.colorbar(img_prep, cax=ax_ins_img, orientation="vertical")
        cb_img.ax.set_xlabel('arb. u.', fontsize=fontsize3)
        cb_img.ax.yaxis.set_major_locator(plticker.LinearLocator(2))
        cb_img.ax.yaxis.set_minor_locator(plticker.LinearLocator(10))
        cb_img.ax.tick_params(labelsize=fontsize3)

        # Map
        axis_map.imshow(frame_bright, norm=frame_cmap_norm, cmap=frame_cmap)
        map_cmap_norm = colors.Normalize(vmin=map_min_display, vmax=map_max_display)
        img_map = axis_map.imshow(map_data, norm=map_cmap_norm, cmap=map_cmap)
        map_scale_bar = AnchoredSizeBar(axis_map.transData, frame_scale, size_vertical=0.2,
                                        label='1 cm', loc=4, pad=0.2, color='w', frameon=False,
                                        fontproperties=fm.FontProperties(size=7, weight='semibold'))
        axis_map.add_artist(map_scale_bar)
        # Add colorbar (right of map)
        hist_bins = map_max_display
        map_range = (map_min_display, map_max_display)
        add_map_colorbar_stats(axis_map, img_map, map_data, map_range,
                               unit=map_unit, bins=hist_bins, stat_color=color_snr)

        # Signal traces and locations on frame
        # plot trace with the chosen ROI pixel
        axis_prep.plot(self.trace_xy[0], self.trace_xy[1], marker='+', color='#54FF00', markersize=marker3)
        axis_xy.plot(self.video_time, self.trace, color=gray_heavy, linestyle='None', marker='+')
        axis_xy.text(0.7, 0.9, 'At {},{} ({})'
                     .format(self.trace_xy[0], self.trace_xy[1], map_data_trace),
                     color=gray_heavy, fontsize=fontsize3, transform=axis_xy.transAxes)

        # Plot trace with a min map value
        min_y, min_x = np.where(map_data == map_min)
        signal_min = self.video_data[:, min_y[0], min_x[0]]
        axis_prep.plot(min_x[0], min_y[0], marker='x', color=color_snr, markersize=marker3)
        axis_min.plot(self.video_time, signal_min, color=gray_heavy, linestyle='None', marker='+')
        axis_min.text(0.7, 0.9, 'Min ({})'.format(map_data[min_y[0]][min_x[0]]),
                      color=gray_heavy, fontsize=fontsize3, transform=axis_min.transAxes)
        # Plot trace with a max map value
        max_y, max_x = np.where(map_data == map_max)
        signal_max = self.video_data[:, max_y[0], max_x[0]]
        axis_prep.plot(max_x[0], max_y[0], marker='x', color=color_snr, markersize=marker1)
        axis_max.plot(self.video_time, signal_max, color=gray_heavy, linestyle='None', marker='+')
        axis_max.text(0.7, 0.9, 'Max ({})'.format(map_data[max_y[0]][max_x[0]]),
                      color=gray_heavy, fontsize=fontsize3, transform=axis_max.transAxes)

        datetime_tuple = time.localtime()
        datetime_tuple = '_' + time.strftime("%Y%m%d_%H%M%S", datetime_tuple)
        # Save map figure as a .png
        fig_snr.savefig(self.project_path_str + '\\' + map_file_name + datetime_tuple + '.png')
        # Save map data as a .csv
        # Format values to have a precision of 2 decimal places
        # decimal_data = [[Decimal(x) for x in row] for row in map_data]
        # map_data_decimal = np.array(decimal_data)
        # map_data_decimal = np.round(map_data_decimal, 2)
        np.savetxt(self.project_path_str + '\\' + map_file_name + datetime_tuple + '.csv',
                   map_data, delimiter=",")

    def apply_prep_step(self, step_button):
        step_name = step_button.accessibleName()
        self.feedback_action('Preparation step {} RUNNING ...'.format(step_name))
        try:
            if step_name == 'Properties':
                # Attempt Props actions
                self.update_parameters(step_name)
                # Generate array of timestamps in ms
                fpms = self.project_props_prp['fps'] / 1000
                t_final = math.floor(self.video_data.shape[0] / fpms)
                self.video_time = np.linspace(start=0, stop=t_final, num=self.video_data.shape[0])
            elif step_name == 'Bin':
                # Attempt Bin actions
                self.update_parameters(step_name)
                if self.project_props_prp['rescale'] == 1:
                    self.video_data = self.video_data_raw
                else:
                    self.video_data = reduce_stack(self.video_data_raw, self.project_props_prp['rescale'])
                self.graphicsView.histogram.setLevels(self.video_data.min(), self.video_data.max())
                self.graphicsView.histogram.setHistogramRange(self.video_data.min(), self.video_data.max())
                self.trace_crosshair.setSize([self.video_data.shape[2] // 20, self.video_data.shape[1] // 20])
                self.traceXSpinBox.setValue(round(self.trace_xy[0] / self.project_props_prp['rescale']))
                self.traceYSpinBox.setValue(round(self.trace_xy[1] / self.project_props_prp['rescale']))
                self.update_inputs(self.kernelPixelsSpinBox)
            elif step_name == 'Mask':
                # Attempt Mask actions
                self.update_parameters(step_name)
                strict = (self.project_props_prp['mask'][0], self.project_props_prp['mask'][1])

                fig_mask = plt.figure(figsize=(12, 8))  # _ x _ inch page
                axis_in = fig_mask.add_subplot(131)
                axis_mask = fig_mask.add_subplot(132)
                axis_masked = fig_mask.add_subplot(133)
                # Common between the two
                for ax in [axis_in, axis_mask, axis_masked]:
                    ax.tick_params(axis='x', labelsize=fontsize4)
                    ax.tick_params(axis='y', labelsize=fontsize4)

                fig_mask.suptitle('Masking: {}, strictness:{}\n({})'
                                  .format('Random_walk', strict, str(self.file_purepath.stem)))
                axis_in.set_title('Input frame')
                axis_mask.set_title('Markers for\nMask')
                axis_masked.set_title('Masked frame')

                frame_masked, self.mask, markers = mask_generate(self.video_data[0], 'Random_walk', strict)
                cmap_frame = SCMaps.grayC.reversed()
                img_in = axis_in.imshow(self.video_data[0], cmap=cmap_frame)
                img_mask = axis_mask.imshow(markers, cmap='magma')
                img_masked = axis_masked.imshow(frame_masked, cmap=cmap_frame)
                datetime = time.strftime("%Y%m%d_%H%M%S", time.localtime())
                fig_mask.savefig(self.project_path_str + '\\' + 'prep_mask_{}.png'.format(datetime))
                self.video_data_unmasked = self.video_data.copy()
                self.video_data = mask_apply(self.video_data, self.mask)

        except ValueError:
            self.reset_progress(step_button)
        except:
            self.reset_progress(step_button)
            exc_type, exc_value, tb = sys.exc_info()
            exc_lineno = tb.tb_lineno
            real_error = str(exc_type) + ' : ' + str(exc_value)
            self.feedback_action('Preparation step {} ERROR at line {} : {}'
                                 .format(step_name, exc_lineno, real_error), success=False)
        else:
            self.step_proceed(step_button)
            self.update_video(frame=self.frame_current)
            self.update_trace()
            self.feedback_action('Preparation step {} PASSED'.format(step_name), success=True)
            if step_button is self.buttonNextPrep_Mask:
                self.feedback_action('Preparation stage PASSED', success=True)

    def apply_proc_step(self, step_button):
        # step_success = True and (random() > 0.5)
        step_name = step_button.accessibleName()
        self.feedback_action('Processing step {} RUNNING ...'.format(step_name))
        try:
            if step_name == 'Normalize':
                # Attempt Normalize actions
                self.update_parameters(step_name)
                if self.normTypeComboBox.currentText() == '0 - 1':
                    self.video_data_unmasked = normalize_stack(self.video_data_unmasked)
                    if self.mask is not None:
                        self.video_data = mask_apply(self.video_data_unmasked, self.mask)
                    else:
                        self.video_data = self.video_data_unmasked
                    self.graphicsView.histogram.setLevels(0, 1)
                    self.graphicsView.histogram.setHistogramRange(-0.5, 1.5)
                    self.update_video()
                    self.update_trace()
                if self.driftCheckBox.isChecked():
                    # TODO confirm drift is working/trying
                    self.feedback_action('Removing Drift from video of shape {}...'.format(self.video_data.shape[1:]))
                    for iy, ix in np.ndindex(self.video_data.shape[1:]):
                        signal_filtered, drift = filter_drift(self.video_data[:, iy, ix], drift_order='exp')
                        self.video_data_unmasked[:, iy, ix] = signal_filtered
                        self.video_data[:, iy, ix] = signal_filtered
                if self.invertCheckBox.isChecked():
                    self.feedback_action('Inverting Signals ...')
                    for iy, ix in np.ndindex(self.video_data.shape[1:]):
                        signal_inverted = invert_signal(self.video_data[:, iy, ix])
                        self.video_data_unmasked[:, iy, ix] = signal_inverted
                        self.video_data[:, iy, ix] = signal_inverted

            elif step_name == 'Filter':
                # Attempt Filter actions
                self.update_parameters(step_name)
                for idx, frame in enumerate(self.video_data_unmasked):
                    # print('\r\tFrame:\t{}\t/ {}'.format(idx + 1, stack_out.shape[0]), end='', flush=True)
                    frame_filtered = filter_spatial(frame, kernel=self.project_props_prc['filter'])
                    # f_filtered = np.ma.masked_where(f_filtered == 0, f_filtered)
                    self.video_data_unmasked[idx, :, :] = frame_filtered
                if self.mask is not None:
                    self.video_data = mask_apply(self.video_data_unmasked, self.mask)
                else:
                    self.video_data = self.video_data_unmasked
                # reapply normalization (filtering smooths min/max)
                if self.normTypeComboBox.currentText() == '0 - 1':
                    self.video_data_unmasked = normalize_stack(self.video_data_unmasked)
                    if self.mask is not None:
                        self.video_data = mask_apply(self.video_data_unmasked, self.mask)
                    else:
                        self.video_data = self.video_data_unmasked
                    self.graphicsView.histogram.setLevels(0, 1)
                    self.graphicsView.histogram.setHistogramRange(-0.5, 1.5)
                    self.update_video()
                    self.update_trace()
            elif step_name == 'SNR':
                # Attempt SNR actions
                self.update_parameters(step_name)
                # TODO check for multiple transients, use last one
                snr_map = map_snr(self.video_data)
                self.export_map(snr_map, 'SNR')
        except:
            self.reset_progress(step_button)
            exc_type, exc_value, tb = sys.exc_info()
            exc_lineno = tb.tb_lineno
            real_error = str(exc_type) + ' : ' + str(exc_value)
            self.feedback_action('Processing step {} ERROR at line {} : {}'
                                 .format(step_name, exc_lineno, real_error), success=False)
        else:
            self.update_video()
            self.update_trace()
            self.step_proceed(step_button)
            self.feedback_action('Processing step {} PASSED'.format(step_name), success=True)
            if step_button is self.buttonNextProc_SNR:
                self.feedback_action('Processing stage PASSED', success=True)

    def apply_analysis_step(self, step_button):
        step_name = step_button.accessibleName()
        self.feedback_action('Analysis step {} RUNNING ...'.format(step_name))
        try:
            if step_name == 'Time Crop':
                # Attempt Time Crop actions
                self.update_parameters(step_name)
                start_frame = self.startFrameSpinBox.value()
                end_frame = self.endFrameSpinBox.value()
                frame_n = end_frame - start_frame
                self.video_data_unmasked = self.video_data_unmasked[start_frame:end_frame, :, :]
                # TODO update relevant UI elements
                self.horizontalScrollBar.setValue(1)
                self.horizontalScrollBar.setMaximum(frame_n)
                self.lcdNumber_frame_n.display(frame_n)
                if self.mask is not None:
                    self.video_data = mask_apply(self.video_data_unmasked, self.mask)
                else:
                    self.video_data = self.video_data_unmasked
                self.update_trace()
                # TODO show Time Crop values on trace plot as vertical lines
            if step_name == 'Analyze':
                self.update_parameters(step_name)
                analysis_type = self.analyzeTypeComboBox.currentText()
                datetime = time.strftime("%Y%m%d_%H%M%S", time.localtime())
                self.feedback_action('Analysis type "{}" RUNNING ...'.format(analysis_type))
                if analysis_type == 'Trace':
                    x, y = self.trace_xy[0], self.trace_xy[1]
                    trace_df = pd.DataFrame({'Time (ms)': self.video_time, 'Trace': self.trace})
                    trace_filename = self.project_path_str + '\\' + 'anys_Trace_{}x{}_{}.csv'. \
                        format(x, y, datetime)
                    trace_df.to_csv(trace_filename, index=False)
                elif analysis_type == 'Trace Analysis':
                    # Create or append to an existing tabular data file (.csv)
                    results_filename = self.project_path_str + '\\' + 'anys_TraceAnalysis_{}.csv'.format(datetime)
                    # results_filename = self.project_path_str + '\\' + 'anys_TraceAnalysis.csv'
                    dur_x_per = self.durationPerSpinBox.value()
                    results_df_columns = ['subject', 'x', 'y', 'Cycle Length', 'SNR',
                                          'Start', 'Activation',
                                          'Duration-20%', 'Duration-80%',
                                          'Duration-90%', 'Duration-{}%'.format(dur_x_per)]
                    # Determine if trace has a single or multiple transients
                    time_ensemble, signal_ensemble, signals, signal_peaks, signal_acts, est_cycle_length \
                        = calc_ensemble(self.video_time, self.trace, crop='center')
                    if signal_ensemble is None:
                        self.feedback_action('Single transient detected during Trace Analysis ensemble ...')
                        x, y = self.trace_xy[0], self.trace_xy[1]
                        cycle_length = np.nan
                        snr, *_ = calculate_snr(self.trace)
                        start, activation = find_tran_start(self.trace), find_tran_act(self.trace)
                        dur_20, dur_80, dur_90, dur_x = \
                            calc_tran_duration(self.trace, 20), calc_tran_duration(self.trace, 80), \
                            calc_tran_duration(self.trace, 90), calc_tran_duration(self.trace, dur_x_per)
                        trace_results = [self.project_props_prp['subject'], x, y, cycle_length, snr,
                                         start, activation, dur_20, dur_80, dur_90, dur_x]
                        results_df = pd.DataFrame([trace_results], columns=results_df_columns)
                    else:
                        self.feedback_action('Multiple transients detected during Trace Analysis ensemble ...')
                        results_df = pd.DataFrame(columns=results_df_columns)
                        for idx, signal in enumerate(signals):
                            x, y = self.trace_xy[0], self.trace_xy[1]
                            cycle_length = est_cycle_length
                            snr, *_ = calculate_snr(signal)
                            start, activation = find_tran_start(signal), find_tran_act(signal)
                            dur_20, dur_80, dur_90, dur_x = \
                                calc_tran_duration(signal, 20), calc_tran_duration(signal, 80), \
                                calc_tran_duration(signal, 90), calc_tran_duration(signal, dur_x_per)
                            trace_results = [self.project_props_prp['subject'], x, y, cycle_length, snr,
                                             start, activation, dur_20, dur_80, dur_90, dur_x]
                            trace_results_dict = {results_df_columns[i]: trace_results[i]
                                                  for i in range(len(results_df_columns))}
                            results_df = results_df.append(trace_results_dict, ignore_index=True)
                            self.feedback_action('Results of transient #{} appended ...\n\t{}'
                                                 .format(idx, trace_results_dict))

                    self.feedback_action('Results to export: \n{}'
                                         .format(results_df))
                    if not os.path.exists(results_filename):
                        # Save results as a .csv
                        self.feedback_action('Trace Analysis results file created : ' +
                                             results_filename.split(sep='\\')[-1])
                        results_df.to_csv(results_filename, index=False)
                    else:
                        self.feedback_action('Trace Analysis results file already exists : ' +
                                             results_filename.split(sep='\\')[-1])
                        # check if columns are identical
                        results_df_old = pd.read_csv(results_filename)
                        if results_df_old.columns != results_df_columns:
                            # combine columns without repeats
                            results_df_columns_new = list(set(results_df_old.columns).union(results_df_columns))
                            results_df = pd.DataFrame(results_df_old, columns=results_df_columns_new)
                            results_df_new = pd.DataFrame(columns=results_df_columns_new)
                            results_df = results_df.append(results_df_new)
                        results_df.to_csv(results_filename, mode='a', index=False)
                elif analysis_type == 'Map: Start':
                    pass
                elif analysis_type == 'Map: Activation':
                    activation_map = map_tran_analysis(self.video_data, find_tran_act, self.video_time)
                    self.export_map(activation_map, 'Activation')
                elif analysis_type == 'Map: Duration':
                    duration = self.durationPerSpinBox.value()
                    duration_map = map_tran_analysis(self.video_data, calc_tran_duration, self.video_time,
                                                     percent=duration)
                    self.export_map(duration_map, 'Duration')
                elif analysis_type == 'Map: Diastolic Interval':
                    raise NotImplementedError
        except:
            self.reset_progress(step_button)
            exc_type, exc_value, tb = sys.exc_info()
            exc_lineno = tb.tb_lineno
            real_error = str(exc_type) + ' : ' + str(exc_value)
            self.feedback_action('Analysis step {} ERROR at line {} : {}'
                                 .format(step_name, exc_lineno, real_error), success=False)
        else:
            # self.update_video()
            # self.update_trace()
            self.step_proceed(step_button)
            self.feedback_action('Analysis step {} PASSED'.format(step_name), success=True)
            if step_button is self.buttonNextAnalysis_Analyze:
                self.feedback_action('Analysis stage PASSED', success=True)

    # TODO set parameters to None when skipped
    def skip_prep_step(self, step_checkbox, step_button):
        step_name = step_button.accessibleName()
        if step_checkbox.checkState():
            self.step_proceed(step_button)
            step_button.setEnabled(False)
            self.feedback_action('Preparation step {} SKIPPED'.format(step_name), success=True)
            if step_button is self.buttonNextPrep_Mask:
                self.feedback_action('Preparation stage PASSED', success=True)
        else:
            self.reset_progress(step_button)

    def skip_proc_step(self, step_checkbox, step_button):
        step_name = step_button.accessibleName()
        if step_checkbox.checkState():
            self.step_proceed(step_button)
            step_button.setEnabled(False)
            self.feedback_action('Processing step {} SKIPPED'.format(step_name), success=True)
            if step_button is self.buttonNextProc_SNR:
                self.feedback_action('Processing stage PASSED', success=True)
        else:
            self.reset_progress(step_button)

    def skip_analysis_step(self, step_checkbox, step_button):
        step_name = step_button.accessibleName()
        if step_checkbox.checkState():
            self.step_proceed(step_button)
            step_button.setEnabled(False)
            self.feedback_action('Analysis step {} SKIPPED'.format(step_name), success=True)
        else:
            self.reset_progress(step_button)

    def feedback_action(self, action_text, success=None):
        time_tuple = time.localtime()
        time_string = '(' + time.strftime("%H:%M:%S", time_tuple) + ') '
        if success is None:
            self.textBrowser_Feedback.setTextColor(QColor(230, 230, 230))  # white text
        else:
            if success:
                self.textBrowser_Feedback.setTextColor(QColor(5, 230, 5))  # green text
            else:
                self.textBrowser_Feedback.setTextColor(QColor(230, 5, 5))  # red text
        self.textBrowser_Feedback.append(time_string + action_text)
        self.textBrowser_Feedback.repaint()

    def setup_next_buttons(self):
        self.next_buttons = [self.buttonNextPrep_Props, self.buttonNextPrep_Bin, self.buttonNextPrep_Mask,
                             self.buttonNextProc_Norm, self.buttonNextProc_Filter, self.buttonNextProc_SNR,
                             self.buttonNextAnalysis_TimeCrop, self.buttonNextAnalysis_Analyze]
        self.buttonNextPrep_Props.released \
            .connect(lambda: self.apply_prep_step(self.buttonNextPrep_Props))
        self.buttonNextPrep_Bin.released \
            .connect(lambda: self.apply_prep_step(self.buttonNextPrep_Bin))
        self.buttonNextPrep_Mask.released \
            .connect(lambda: self.apply_prep_step(self.buttonNextPrep_Mask))
        self.buttonNextProc_Norm.released \
            .connect(lambda: self.apply_proc_step(self.buttonNextProc_Norm))
        self.buttonNextProc_Filter.released \
            .connect(lambda: self.apply_proc_step(self.buttonNextProc_Filter))
        self.buttonNextProc_SNR.released \
            .connect(lambda: self.apply_proc_step(self.buttonNextProc_SNR))
        self.buttonNextAnalysis_TimeCrop.released \
            .connect(lambda: self.apply_analysis_step(self.buttonNextAnalysis_TimeCrop))
        self.buttonNextAnalysis_Analyze.released \
            .connect(lambda: self.apply_analysis_step(self.buttonNextAnalysis_Analyze))

    def setup_skip_buttons(self):
        self.skip_checkboxes = [self.checkBoxSkipPrep_Bin.stateChanged, self.checkBoxSkipPrep_Mask.stateChanged,
                                self.checkBoxSkipProc_Filter.stateChanged, self.checkBoxSkipProc_SNR.stateChanged,
                                self.checkBoxSkipAnalysis_TimeCrop.stateChanged]
        self.checkBoxSkipPrep_Bin.stateChanged \
            .connect(lambda: self.skip_prep_step(self.checkBoxSkipPrep_Bin, self.buttonNextPrep_Bin))
        self.checkBoxSkipPrep_Mask.stateChanged \
            .connect(lambda: self.skip_prep_step(self.checkBoxSkipPrep_Mask, self.buttonNextPrep_Mask))
        self.checkBoxSkipProc_Filter.stateChanged \
            .connect(lambda: self.skip_proc_step(self.checkBoxSkipProc_Filter, self.buttonNextProc_Filter))
        self.checkBoxSkipProc_SNR.stateChanged \
            .connect(lambda: self.skip_proc_step(self.checkBoxSkipProc_SNR, self.buttonNextProc_SNR))
        self.checkBoxSkipAnalysis_TimeCrop.stateChanged \
            .connect(lambda: self.skip_analysis_step(self.checkBoxSkipAnalysis_TimeCrop,
                                                     self.buttonNextAnalysis_TimeCrop))

    def step_proceed(self, step_button):
        i = 1
        while self.next_buttons[i - 1] is not step_button:
            i += 1
        if i < len(self.next_buttons):
            self.reset_progress(self.next_buttons[i])

    def reset_progress(self, step_button):
        i = 1
        step_button.setEnabled(True)
        if step_button is self.buttonNextPrep_Bin:
            self.checkBoxSkipPrep_Bin.setEnabled(True)
            self.checkBoxSkipPrep_Bin.setChecked(False)
        elif step_button is self.buttonNextPrep_Mask:
            self.checkBoxSkipPrep_Mask.setEnabled(True)
            self.checkBoxSkipPrep_Mask.setChecked(False)
        elif step_button is self.buttonNextProc_Filter:
            self.checkBoxSkipProc_Filter.setEnabled(True)
            self.checkBoxSkipProc_Filter.setChecked(False)
        elif step_button is self.buttonNextProc_SNR:
            self.checkBoxSkipProc_SNR.setEnabled(True)
            self.checkBoxSkipProc_SNR.setChecked(False)
        elif step_button is self.buttonNextAnalysis_TimeCrop:
            self.checkBoxSkipAnalysis_TimeCrop.setEnabled(True)
            self.checkBoxSkipAnalysis_TimeCrop.setChecked(False)
        while self.next_buttons[i - 1] is not step_button:
            i += 1
        while i < len(self.next_buttons):
            cur_button = self.next_buttons[i]
            if not cur_button.isEnabled():
                break
            if cur_button is self.buttonNextPrep_Bin:
                self.checkBoxSkipPrep_Bin.setEnabled(False)
            elif cur_button is self.buttonNextPrep_Mask:
                self.checkBoxSkipPrep_Mask.setEnabled(False)
            elif cur_button is self.buttonNextProc_Filter:
                self.checkBoxSkipProc_Filter.setEnabled(False)
            elif cur_button is self.buttonNextProc_SNR:
                self.checkBoxSkipProc_SNR.setEnabled(False)
            elif cur_button is self.buttonNextAnalysis_TimeCrop:
                self.checkBoxSkipAnalysis_TimeCrop.setEnabled(False)
            cur_button.setEnabled(False)
            i += 1


if __name__ == '__main__':
    # create the GUI application
    app = QApplication(sys.argv)
    # instantiate and show the main window
    ks_mdi = WindowMDI()
    ks_mdi.show()
    # start the Qt main loop execution, exiting from this script
    # with the same return code as the Qt application
    sys.exit(app.exec_())
